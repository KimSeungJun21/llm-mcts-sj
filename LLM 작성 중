https://www.ibm.com/kr-ko/topics/large-language-models (참고)
대규모 언어 모델(LLM)
방대한 양의 데이터를 학습하여 자연어 및 기타 유형의 콘텐츠를 이해하고 생성
광범위한 작업을 수행할 수 있는 기초 모델의 범주 

https://www.hpe.com/kr/ko/what-is/large-language-model.html (참고)
1. 데이터 수집 : 다양한 소스에서 다양한 텍스트 데이터 세트 수집
2. 전처리 : 수집한 텍스트 데이터를 정리 및 표준화
3. 토큰화 : 전처리한 텍스트를 토큰이라는 작은 단위로 나눈다.
4. 아키텍처 선택 : 트랜스포머 모델 등 적절한 딥 러닝 아키텍처를 선택
5. 교육 : 해당 모델이 데이터를 학습하게 하는 실제 훈련 과정
6. 결과 개선 : 수정과 세부 조정을 통해 모델을 최적화
7. 평가 : 모델의 결과물과 정확도를 평가
8. 배포 : 사용할 실제 시스템에 모델을 배포


https://www.youtube.com/watch?v=-vnxFKHmKjc
-> ChatGPT의 원리 
